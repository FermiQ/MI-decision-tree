{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e94ff797bbd96cbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lab 3. Linear regression & gradient descent\n",
    "\n",
    "#### Table of contents\n",
    "\n",
    "1. Overview\n",
    "2. Diffusion background\n",
    "3. Prepare the data\n",
    "    - 3.1. Load the data\n",
    "    - 3.2. Clean the data\n",
    "    - 3.3. Standardize the data\n",
    "4. Cost function\n",
    "5. Gradient descent\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "The goal of this Lab is to extract the activation energy of water in its liquid state. This will be achieved by performing linear regression of water diffusion coefficients at various temperatures. You will learn how to clean and plot data, and perform linear regression with gradient descent.\n",
    "\n",
    "## 2. Diffusion background\n",
    "\n",
    "Diffusion is the net movement of anything (for example, atom, ions, molecules) from a region of higher concentration to a region of lower concentration. Diffusion is driven by a gradient in concentration. For example, if you spray perfume at one end of a room eventually the gas particles will be all over the room [wikipedia]. Even \n",
    "if there is no concentration gradient the process of molecular diffusion has ceased and is instead governed by the process of self-diffusion, originating from the random motion of the molecules. Molecular diffusion is a thermally activated process and therefore governed by an Arrhenius equation:\n",
    "\n",
    "$D = Ae^{-\\frac{E_A}{k_BT}}$\n",
    "\n",
    "with $D$, $A$, $E_A$, $k_B$ and $T$ the diffusion coefficient (at temperature T), a prefactor, the activation energy, Boltzmann constant and the temperature, respectively. Diffusion coefficients represent how long it takes a particular substance to move through a particular medium and has for units distance$^2$/time. The activation energy represents the height of the energy barrier the substance has to overcome to succesfully perform a moving step and its units is an energy. A rearrangement of the Arrhenius equation taking natural logarithms gives the linear function:\n",
    "\n",
    "$\\ln{D} = \\ln{A} - \\frac{E_A}{k_BT}$\n",
    "\n",
    "A plot of the natural logarithm of the diffusion coefficient $\\ln{D}$ against $1/T$ will be a straight line if the substance diffusing obeys the Arrhenius equation and one can extract the activation energy $E_A$ as the slope. In this lab, based on diffusion coefficients of water molecules at different temperatures, we will extract the corresponding activation energy.\n",
    "\n",
    "## 3. Prepare the data\n",
    "\n",
    "Several publications provide values of self-diffusion coefficients of water at different temperatures (we will use those summarized [here](https://dtrx.de/od/diff/)). To help you getting started, these data were compiled and stored in the file `water_diffusion.csv` that you should get from the blackboard and upload to your workspace.\n",
    "\n",
    "### 3.1. Load the data\n",
    "\n",
    "__Q.1.__ Load the dataset `water_diffusion.csv` as a pandas DataFrame and store it into the variable `wd`. Write your answer between the `### BEGIN SOLUTION` and `### END SOLUTION` comment lines (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # We first load pandas\n",
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9ea8f4d3cc6cd54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's have a look at the DataFrame `wd` more in detail. If you get errors in the following code lines, this means you did not load the DataFrame properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62c7fbe3d2d95ace",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eba22e5be3d2f23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48f9fe535b475bf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Based on last week's Lab we see that there are 56 entries, 3 columns and no null objects. We note that the Temp (in C and K) are both strings, indeed, these entries are a mixture of numbers and letter characters therefore Python identifies them as `str`. Diffusion coeffecients are floats. \n",
    "\n",
    "### 3.2. Clean the data\n",
    "\n",
    "Let's prepare the diffusion data. Here we just need to create a Series with all diffusion coefficients. Let's call this Series `diff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-444c54965ca8d27b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "diff = wd['D (um2/ms)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd5cdf68e8671a57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's create the List `y` containing the log of the diffusion coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "y = []\n",
    "for di in diff:\n",
    "    y.append(math.log(di))\n",
    "print(y)\n",
    "# Note that this previous 4-lines of code can be written in 1 as the nested loop: y = [np.log(di) for di in diff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d7c5aa0dbd930d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here is the line-by-line explanation of the above code:\n",
    "\n",
    "- we first import the math package to use its method `log`\n",
    "- we initialize an empty List `y`\n",
    "- we loop over the elements of diff and store each in the variable `di`\n",
    "- we append at the end of the List `y` the natural log of the variable `di`\n",
    "- we print the List `y`\n",
    "\n",
    "You can verify that, for example, the log of the first value of the Series `diff`: 1.149 gives the results stored in the first element of the List `y`: 0.13889199886661865.\n",
    "\n",
    "__Q.2.__ Create the Series `temp` containing the temperature in Kelvin of the measurments reported in the DataFrame `wd`. Do not clean the data for now, we will do it right after. Just put the raw temperatures with the 'K' as it is in the original DataFrame (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7414b844072d57f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's now transform the `temp` Series into a List, clean the data and store the inverse temperature in the list `x`. Again, if you get errors when you execute the following lines, you did not answer right question 2 (or even 1) and you should get back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = list(temp)\n",
    "x = [1/float(ti.split('K')[0]) for ti in temp_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-40acd32dd9de31c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here is a quick explanation of the previous lines of code:\n",
    "\n",
    "- We first transform the Series `temp` to the List `temp_list`\n",
    "- Here is a nested loop. We loop over elements `ti` of the List `temp_list`\n",
    "- We split each elements `ti` at the character 'K' which should return a List of two elements (because there is only one instance of 'K' in each element `ti`): the number temperature and an empty string (because there is nothing after the character 'K')\n",
    "- We take the number (element in the list at index 0: `ti.split('K')[0]`) and transform it to a float\n",
    "- We finally take the inverse of this float and store it into the List `x` \n",
    "\n",
    "We now have two lists, `x` and `y` containing the inverse temperature and the log of the corresponding diffusion coefficients, respectively. We can plot $y = f(x)$ to see how these quantities correlate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x,y,marker='o',lw=0)\n",
    "plt.xlabel('1/T (K)')\n",
    "plt.ylabel('D (um2/ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d2a86088044f548",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This looks quite linear.\n",
    "\n",
    "### 3.3. Standardize the data\n",
    "\n",
    "Feature Scaling is a technique to standardize the independent features present in the data in a fixed range. It is performed during the data pre-processing to handle highly varying magnitudes or values or units. We will see that feature scaling is essential when dealing with multiple features however it is also useful to help gradient descent  converge faster.\n",
    "\n",
    "Standardization is a very efficient technique to re-scales a feature value so that it has distribution with 0 mean value and variance equals to 1.\n",
    "\n",
    "$x_{\\text{std}}^{(i)} = \\frac{x^{(i)}-\\mu}{\\sigma}$\n",
    "\n",
    "with $\\mu$ and $\\sigma$ the mean and standard deviation of the values of $x^{(i)}$.\n",
    "The mean and standard deviation of the value of a list can be accessed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mu = np.mean(x)\n",
    "std = np.std(x)\n",
    "print(mu,std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d73da32a250c177",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Q.3.__ Complete the function below that performs standardization of a list of number taken as argument. The function should return the standardized list. You should verify that the mean of the standardized data is close to zero and that the standard deviation is close to 1.0 (2 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(x_list):\n",
    "    mu = np.mean(x_list)\n",
    "    std = np.std(x_list)\n",
    "    x_standard = []\n",
    "    ### BEGIN SOLUTION\n",
    "    ### END SOLUTION\n",
    "    return x_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e5cb78fe81e71b67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's have a look at the plot based on the standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standard = standard(x)\n",
    "y_standard = standard(y)\n",
    "plt.plot(x_standard,y_standard,marker='o',lw=0)\n",
    "plt.xlabel('1/T (K)')\n",
    "plt.ylabel('D (um2/ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4532a9e3a0952e58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Both data should now vary within similar range.\n",
    "\n",
    "## 4. Cost function\n",
    "\n",
    "We would like now to perform linear regression of the standardized data.\n",
    "As discussed in the lecture, this corresponds to minimizing the cost function:\n",
    "\n",
    "$J\\left(\\theta_0,\\theta_1\\right) = \\frac{1}{2m}\\sum_{i=1}^{m}\\left(h(x^{(i)})-y^{(i)}\\right)^2$\n",
    "\n",
    "with respect to the coefficients $\\theta_0$ and $\\theta_1$, given the hypothesis $h$ defined as:\n",
    "\n",
    "$h(x^{(i)}) = \\theta_0+\\theta_1x^{(i)}$\n",
    "\n",
    "$x^{(i)}$ and $y^{(i)}$ represent the input data and the corresponding target output, respectively, and $m$ the number of input examples. Let's first define the cost function.\n",
    "\n",
    "__Q.4.__ Complete the cost function below that takes as arguments the two coefficients $\\theta_0$ and $\\theta_1$ (`t0` and `t1`) and the two lists `x` and `y` of data (2 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(t0,t1,x,y):\n",
    "    m = len(x) # this is the number of examples in the data\n",
    "    err = 0.0 # We initialize the variable err\n",
    "    ### BEGIN SOLUTION\n",
    "    ### END SOLUTION\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34c762a1671c6786",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5. Gradient descent\n",
    "\n",
    "We now wish to find the optimal parameters $\\theta_0$ and $\\theta_1$ that minimize the cost function. We will implement gradient descent. The idea is to update the coefficients $\\theta_0$ and $\\theta_1$ by changing their values such that it will bring the cost function toward smaller and smaller values. The update of the coefficients $\\theta_0$ and $\\theta_1$ corresponds to the mathematical equations:\n",
    "\n",
    "$\\theta_0 := \\theta_0-\\alpha\\frac{1}{m}\\sum_{i=1}^m\\left(h(x^{(i)})-y^{(i)}\\right)$\n",
    "\n",
    "$\\theta_1 := \\theta_1-\\alpha\\frac{1}{m}\\sum_{i=1}^m\\left(h(x^{(i)})-y^{(i)}\\right)x^{(i)}$\n",
    "\n",
    "with $\\alpha$ the learning rate. It is important that these two equations are updated simultaneously. This means that in the second equation, the hypothesis was computed based on $\\theta_0$ coefficient __before__ its update in the first equation! A simple way to satisfy this is to evaluate $h$ beforehand and then pass it to the function to update the coefficients $\\theta_0$ and $\\theta_1$.\n",
    "\n",
    "__Q.5.__ Complete the function below to update $\\theta_0$ (`t0`). The function takes the current value of `t0`, the learning rate $\\alpha$, the hypothesis $h$ (the list $\\theta_0+\\theta_1x^{(i)}$ of length $m$) and the target values of the data $y$. Just define the variable `grad_t0` as the gradient of the cost function with respect to $\\theta_0$. You can also look at the gradient descent code below to understand better the shape of the arguments (2 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_t0(t0,alpha,h,y):\n",
    "    m = len(y)\n",
    "    grad_t0 = 0.0\n",
    "    ### BEGIN SOLUTION\n",
    "    ### END SOLUTION\n",
    "    new_t0 = t0-alpha*grad_t0\n",
    "    return new_t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e1410fb97e937f49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Q.6.__ Complete the function below to update `t1`. Just define the variable `grad_t1` as the gradient of the cost function with respect to $\\theta_1$ (2 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_t1(t1,alpha,h,x,y):\n",
    "    m = len(y)\n",
    "    grad_t1 = 0.0\n",
    "    ### BEGIN SOLUTION\n",
    "    ### END SOLUTION\n",
    "    new_t1 = t1-alpha*grad_t1\n",
    "    return new_t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5feee670258f7903",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you have done everything right, the code below should perform gradient descent based on the 3 functions you implemented and it should converge in approximately 100 steps. Read carfully the commands and be sure you understand the whole code. Try to play with the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-428fc5f75c5b207d",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we initialize t0 and t1\n",
    "t0, t1 = 0,0\n",
    "# Define the learning rate alpha\n",
    "alpha = 0.1\n",
    "# Define m as the number of examples\n",
    "m = len(x_standard)\n",
    "\n",
    "# We will loop for 100 steps\n",
    "for step in range(1,100):\n",
    "\n",
    "    # This is the hypothesis computed with t0 and t1\n",
    "    h = [t0+t1*x_standard[i] for i in range(m)]\n",
    "    \n",
    "    # Here we perform the update of the coefficients\n",
    "    t0 = update_t0(t0,alpha,h,y_standard)\n",
    "    t1 = update_t1(t1,alpha,h,x_standard,y_standard)\n",
    "    \n",
    "    # We now compte the error based on the cost function defined above and the updated coefficients t0 and t1\n",
    "    err = J(t0,t1,x_standard,y_standard)\n",
    "    \n",
    "    # Here we print the step number, t0, t1 and the error value\n",
    "    print(step,t0,t1,err)\n",
    "\n",
    "# We print the final value of the coefficients\n",
    "print(\"Final values of the coefficients t0 and t1:\", t0, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c381513937ee7a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Based on the optimized coefficients, we can plot the hypothesis $h$ that should reproduce the data quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the original data\n",
    "plt.plot(x_standard,y_standard,marker='o',lw=0,label=\"data\")\n",
    "# Here define a list of 100 numbers between min and max of x_standard\n",
    "x_fit = np.linspace(min(x_standard),max(x_standard),100)\n",
    "# We compute the value of the hypothesis over x_fit based on the final coefficients t0 and t1\n",
    "y_fit = [t0+t1*xi for xi in x_fit]\n",
    "# Plot the straight line\n",
    "plt.plot(x_fit,y_fit,lw=1,label=\"best fit\")\n",
    "plt.xlabel('1/T (K)')\n",
    "plt.ylabel('D (um2/ms)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6ad50764f09f06b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have obtained the values of the standardized regression coefficients $\\theta_0$ and $\\theta_1$. The regression coefficients of the original data $\\beta_0$ and $\\beta_1$ can be deducted as:\n",
    "\n",
    "$\\beta_1 = \\theta_1\\frac{\\sigma_y}{\\sigma_x}$\n",
    "\n",
    "$\\beta_0 = \\frac{1}{m}\\sum_i (y^{(i)}-\\beta_1x^{(i)})$\n",
    "\n",
    "with $\\sigma_x$ and $\\sigma_y$ the standard deviation of the initial $x$ and $y$ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = t1*np.std(y)/np.std(x)\n",
    "b0 = np.mean([y[i]-b1*x[i] for i in range(m)])\n",
    "print(\"The regression coefficients b0 and b1 are:\", b0, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7692c6dc23296fd2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Given the Boltzmann constant $k_B$=8.61733$\\times$10$^{-5}$ eV/K, the activation energy (in eV) of liquid water can be computed as $E_A = -k_B\\beta_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-590e10bc9ba52a7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "kB = 8.61733*1e-5\n",
    "EA = -b1*kB\n",
    "print(\"The activation energy of liquid water is:\", EA, \"eV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c694bc75c71a9a92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here you should find an activation energy of approximately 0.2 eV. If you find a very different number you might want to review the steps that brought you here."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
